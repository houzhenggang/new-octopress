<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: java | Hegel2011的博客]]></title>
  <link href="http://octopresszhangyu.herokuapp.com/blog/categories/java/atom.xml" rel="self"/>
  <link href="http://octopresszhangyu.herokuapp.com/"/>
  <updated>2014-12-28T15:25:49+08:00</updated>
  <id>http://octopresszhangyu.herokuapp.com/</id>
  <author>
    <name><![CDATA[Hegel 2011]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Spring中的CRON]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/28/springzhong-de-cron/"/>
    <updated>2014-12-28T15:12:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/28/springzhong-de-cron</id>
    <content type="html"><![CDATA[<p>在<a href="/blog/2014/09/11/webrong-qi-zhong-tong-guo-springtian-jia-jobren-wu/">Web容器中通过Spring添加Job任务</a>一文中，
已经提过在spring中增加例行任务。只是当时提交的任务仅限于间隔一段时间后执行，比如每分钟执行一次，因此使用
<code>period</code> 和 <code>delay</code>两个参数就够了。</p>

<p>这次新遇到的需求是要求定点执行，比如固定在夜间23:30启动，这时候就需要cron了。好在Spring 4.0版
开始已经支持cron，配置起来也很简洁。</p>

<p>首先，在<code>spring-mvc.xml</code>中增加要定期执行的类作为bean，作用是把要定期执行的类交给spring扫描</p>

<p><code>xml
&lt;bean id="LastDayDevicePackorderlogRefreshTaskExecutor" class="com.sanss.toolbar.job.LastDayDevicePackorderlogRefreshTaskExecutor"&gt;
&lt;/bean&gt;
</code></p>

<p>其次，在这个类上使用标注<code>@EnableScheduling</code>，让spring意识到这是一个定期调度启动的任务。</p>

<p>```java
@EnableScheduling
public class LastDayDevicePackorderlogRefreshTaskExecutor implements Runnable {</p>

<p>}
```</p>

<p>最后，是在具体要启动的method上标注<code>@Scheduled(cron = "0 * * * * *")</code>，以此给出具体的执行安排。<br/>
标注中cron的具体含义可以见下面的注释。</p>

<p>```java</p>

<pre><code>/*
 * 一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。
 *
 * 按顺序依次为 秒（0~59）
 *
 * 分钟（0~59）
 *
 * 小时（0~23）
 *
 * 天（月）（0~31，但是你需要考虑你月的天数）
 *
 * 月（0~11）
 *
 * 天（星期）（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT）
 *
 * 7.年份（1970－2099）
 */
@Scheduled(cron = "0 * * * * *")
public void run() {
    // TODO Auto-generated method stub
    // doit();
    logger.info("定期触发");
}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Passionate Programmer]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/21/tpp/"/>
    <updated>2014-12-21T17:21:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/21/tpp</id>
    <content type="html"><![CDATA[<p>中文翻译是《我编程，我快乐--程序员职业规划之道》。在陪老婆做头发的过程中，看完了这本书。
本书还有一个更大名鼎鼎的名字：My Job Went to India。整本书其实更确切地说是如何
追求成为卓越的软件开发者。中文名字起的其实有点文不对题。</p>

<p>书中比较有意义的是提到了程序语言的选择是一种投资，低风险必然低回报，而高风险可能高回报也可能
无回报。所以对于选择小众还是大众化的区别和结果给了完整的分析。
而同时，对于继续在大众语言中立足的开发者而言，作者提出来因为需求的提高，初级程序员会增多，
而对高级开发者的需求也会因此增强。也算是给高级开发者指明了出路。此外，作者也区分了经理和
带路人的区别。经理的职责并非是替补，事实上经理的主要职责是确定事情的优先级，保证部门的运行
效率等。这也是管理真正的目的。</p>

<p>整本书读起来还是比较轻松的，首先当然是因为这本书确实很薄。其次，书中很多内容也确实和我一直
以来做的差不多。其实对于小公司工作的人来讲，书中提到的做法也几乎是一种自然而且必然的选择。</p>

<p>而保持激情一切一切的关键在于当代社会确实需要软件，也确实需要程序员。同时由于
软件开发者智力劳动的属性，注定必须强调自我驱动，很难完全规范化和流水线化，因此从业人员的能力对产出
也会产生极大的差别化结果。
 所以在这个时代，安心地当个软件开发者还是有出路且挺幸福的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[独一无二者计数问题（ count-distinct）]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/17/du-%5B%3F%5D-wu-er-zhe-ji-shu-wen-ti-%28-count-distinct%29/"/>
    <updated>2014-12-17T16:14:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/17/du-[?]-wu-er-zhe-ji-shu-wen-ti-(-count-distinct)</id>
    <content type="html"><![CDATA[<p>最近分析一个大日志文件，9亿条记录近300GB的数据。终于体会到一点大数据处理的意思。</p>

<p>之前根据日志，统计出里面各个域名的pv还算简单。为了开发方便，利用了Redis，开10个java线程，分别扫描不同的行，并把domain做关键字写入redis并不断计数，最后从中读出全部的值并排序。
整个过程主要开销在扫描方面。此时瓶颈出在redis上，基本上5个java线程可以把redis的cpu性能榨干。</p>

<p>9亿条数据分析出来了七十几万个域名，而redis处理70w个key，消耗的内存在100MB以内，所以整个运行跑上几个小时就能得到想要的结果了。</p>

<p>但是，客户进一步提出要分析每个domain下独立访问的用户数量是多少。这下子可就犯难了。
因为按照传统的做法，碰到需要计算独立用户的需求会建立一个集合，然后把标识往里push，最后获取一下这个set的大小，就可以得到独立用户的数量。
然而，如果对70w个域名都分别建立一张访问用户的set，则存储的开销实在太大。这意味着key-value的数量将是70w的几千甚至几万倍。
然后看了一下redis新增加的数据结构类型，发现redis中的hyperloglogs是为此种任务而生的。</p>

<h2>HyperLogLog和count-distinct problem</h2>

<p>建立一个集合并把数据放入，最后计算集合的大小是一种精确的求值方式。而HyperLogLog则是一种会损失一些细节但可以获得很好的近似值的估算方式。</p>

<p>这种算法的核心思想就是MD5+Bitmap。通过某种Hash算法，比如MD5，可以把千变万化的取值收敛成有限的值，而因为这些值也很大，所以可以认为重复的比例会很低。然后，应用Bitmap来表示这些映射结果是否已存在，最后就是计算这个Bitmap中已存在值的数量。尽管损失一些细节，也不是完全精确，但结果是足够准确了。而经过Hash的收敛，再经过Bitmap的收敛，对空间的需求就会变得少了许多许多，也就可以应用于更多关键字的计数。</p>

<p>以我自己对某个域名按两种方式都运行后得到的结果，分别对比如下：</p>

<p>精确的：1687，估计的：1685<br/>
精确的：93869，估计的：94097<br/>
精确的：305084，估计的：305281</p>

<p>而这种方式最大的好处，自然就是对count-distinct这类问题统计起来毫无压力了,同时得到的数据也足够好用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[并发的ab测试和校验码对并发状况处理的盲区]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/11/bing-fa-de-abce-shi-he-xiao-yan-ma-dui-bing-fa-zhuang-kuang-chu-li-de-mang-qu/"/>
    <updated>2014-12-11T21:55:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/11/bing-fa-de-abce-shi-he-xiao-yan-ma-dui-bing-fa-zhuang-kuang-chu-li-de-mang-qu</id>
    <content type="html"><![CDATA[<p>某个报障称我们的短信轰炸拦截无效，听到后感觉比较奇怪，因为此限制已经加上并且经过测试验证。
但提供的素材上，单个用户确实同时收到了多条短信。于是又检查了一遍代码，发现问题可能出在并发上。</p>

<p>限制的过程是这样的：</p>

<ol>
<li>取出session中的校验码并与请求中的参数进行比较，通过的进入第2步，如失败则直接进入第3步；</li>
<li>发送短信；</li>
<li>刷新校验码。</li>
</ol>


<p>而如果扫描软件获取验证码后，同时交给多个线程并发发起请求，因为第一步执行的速度较快，而下发短信的请求处理较慢，
极其可能在执行第3步之前，另外几个请求也都通过了第一步的检查，从而可以进行第二步。</p>

<p>然后就是要验证这种猜测是否成立。由于扫描软件并不是我的，所以需要自己模拟这个请求，而又由于一些陷阱，导致整个验证也
颇费了一番周折。</p>

<h3>第一个坑： ! 和 &amp;都是shell的特殊字符</h3>

<p>最简单的模拟无非就是ab测试（ApacheBench），</p>

<p><code>ab -c 5 -n 10  http://xxx.com/portal/get\!validate.action?user_id=1xxxx\&amp;verfiyCode=5614</code></p>

<p>但是，一开始并没有在!和&amp;前面加上转移符号，所以运行失败</p>

<h3>第二个坑： 需要提前放入session</h3>

<p>一开始并没有搞清楚shell执行ab失败只是因为缺乏转义符号，于是尝试使用编写客户端代码解决。首先使用了Java的Jersey，
因为手头一个项目最近使用这个也比较顺手。运行之后发现每次都是返回404的错误。而在浏览器中，即使验证码不对，也会显示
正确的jsp。换了一台机器后，发现自己犯了个低级错误，因为验证码是存放在session里面的，而Jersey的普通请求不会
带cookie上去，因此就得到了错误的响应。</p>

<p>于是想着给Jersey的请求加上cookie消息头。一番考察后，被告知Jersey原生态并不支持直接加cookie，于是决定还是换用
ruby的rest-client。</p>

<p>```ruby
require 'rest-client'</p>

<p>jsp = "http://xxx.com/portal/";
passportUrl = 'http://xxx.com!validate.action?user_id=1xxxxxx&amp;verfiyCode=9813';</p>

<p>def s
  response = RestClient.get(jsp)
  @cookies = response.cookies</p>

<p>  @cookies['JSESSIONID'] = '74113695C0FB915393AE69DD63EAE088'
  p @cookies
  #puts response.body</p>

<p>  5.times do |n|</p>

<pre><code> response = RestClient.get(passportUrl, cookies: @cookies)
</code></pre>

<p>  end
  puts response.body
end</p>

<p>s()
```</p>

<p>手工填入浏览器中的校验码，运行正常。但ruby的单线程运行方式下，
模拟不出并发的效果，所以还是需要回到ab测试上。</p>

<p>最后的结果倒是很简单，给路径加上转义并添加cookie头即可：</p>

<p><code>ab -c 5 -n 10 -H "Cookie: JSESSIONID=74113695C0FB915393AE69DD63EAE088;" http://xxx.com/portal/get\!validate.action?user_id=1xxxx\&amp;verfiyCode=5614</code></p>

<p>这条命令基本上可收到5条短信，因为并发是5个。</p>

<h3>解决的办法</h3>

<p>最偷懒且管用的办法是使用<code>synchronized</code>关键字。需要注意的是两点：</p>

<p>第一， synchronized锁住的只是对象对应的代码段，所以适用于单例对象或者是static method。也可以通过
下面的方式，让锁住类对象来实现static的效果。</p>

<p>```java</p>

<pre><code>   synchronized (Controller.class) {  

    }
</code></pre>

<p>```</p>

<p>第二， 因为是只有一个线程可以执行代码，这个锁的影响还是很大的，所以要确保锁住的代码快足够小，操作足够快，
才不至于影响业务的性能。在此采用这么粗的锁，也是因为从session中验证校验码并删除是足够短的处理逻辑。</p>

<p>```java
synchronized private static void validCode(HttpSession sesson, String code) {
  result = false;
  if (StringUtils.equal(session.getAttribute("rand1"), code)) {</p>

<pre><code>result = true;
</code></pre>

<p>  }
  session.removeAttribute("rand1");
  return result;
}
```</p>

<h3>得到的教训</h3>

<p>部分业务逻辑在设计和实现时必须考虑并发的情况，尽管这个确实有点难度。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tomcat7 采用 Redis作为session Store - 2]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/11/19/tomcat7-cai-yong-rediszuo-wei-session-store-2/"/>
    <updated>2014-11-19T15:57:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/11/19/tomcat7-cai-yong-rediszuo-wei-session-store-2</id>
    <content type="html"><![CDATA[<p>在<a href="/blog/2014/07/14/tomcat7-cai-yong-rediszuo-wei-session-store/">Tomcat7 采用 Redis作为session Store</a>中，使用了redis作为tomcat的session共享。
在打过几个补丁后，基本也算运作正常。只是偶尔总是有些null的session需要定期清理。而当时的作者已经近2年没再处理相关的pull request，所以我提交到了另外一个库中。</p>

<p>上个月发现作者又回来了，接受处理了一系列的pull request并且还增加了一些新的配置。于是做了一下更新。</p>

<p>原本提过需要3个包：</p>

<ol>
<li><del>tomcat-redis-session-manager-1.2-tomcat-7.jar</del></li>
<li><del>jedis-2.0.0.jar</del></li>
<li><del>commons-pool-1.3.jar</del></li>
</ol>


<p>这次作者终于在readme中也加以了描述，并且更新了版本：</p>

<ol>
<li>tomcat-redis-session-manager-VERSION.jar</li>
<li>jedis-2.5.2.jar</li>
<li>commons-pool2-2.2.jar</li>
</ol>


<p>在context.xml中的配法也做了一些调整，主要是类名发生了变化，
```xml
<Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" />
&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager"</p>

<pre><code>     host="localhost" &lt;!-- optional: defaults to "localhost" --&gt;
     port="6379" &lt;!-- optional: defaults to "6379" --&gt;
     database="0" &lt;!-- optional: defaults to "0" --&gt;
     maxInactiveInterval="60" &lt;!-- optional: defaults to "60" (in seconds) --&gt;
     sessionPersistPolicy="ALWAYS" &lt;!-- optional: defaults to "DEFAULT" --&gt; /&gt;
     sessionPersistPolicies="PERSIST_POLICY_1,PERSIST_POLICY_2,.." &lt;!-- optional --&gt;
     sentinelMaster="SentinelMasterName" &lt;!-- optional --&gt;
     sentinels="sentinel-host-1:port,sentinel-host-2:port,.." &lt;!-- optional --&gt;
    connectionPoolMaxIdle="20"
     connectionPoolMaxTotal="500" 
</code></pre>

<p> /></p>

<p>```</p>

<p>另外就是增加了sessionPersistPolicies，建议选择<code>SAVE_ON_CHANGE</code>，如果选择<code>ALWAYS_SAVE_AFTER_REQUEST</code>，更容易诱发写竞争。而且有些场合，如果在request结束之后再写入，
中间的状态可能时间会拖得太长。如果真的对竞争情况很敏感的场合，就需要自己手动设置锁。</p>

<h3>github上把原作者的提交合并到自己的库中</h3>

<p>同把自己的修改贡献给对方类似，只不过这种pull request需要换成base是自己的库，而head则是原作者库，然后新建pull request，github就会列出发生过的变化。
这时候又会产生两种结局，其一是github可以自动合并，则再点击按钮即可，另一种是自动合并失败，会提示在本机先建分支，再pull原作者的分支，冲突解决（修改完毕）后合并回自己的主分支，
然后再push到github。push成功后，github会自动关闭这个pull request。</p>
]]></content>
  </entry>
  
</feed>
