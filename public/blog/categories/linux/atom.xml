<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: linux | Hegel2011的博客]]></title>
  <link href="http://octopresszhangyu.herokuapp.com/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://octopresszhangyu.herokuapp.com/"/>
  <updated>2013-03-28T16:08:54+08:00</updated>
  <id>http://octopresszhangyu.herokuapp.com/</id>
  <author>
    <name><![CDATA[Hegel 2011]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[About AWK]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2013/02/19/about-awk/"/>
    <updated>2013-02-19T14:52:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2013/02/19/about-awk</id>
    <content type="html"><![CDATA[<p>受 <a href="http://coolshell.cn/articles/9070.html">AWK简明教程</a> 的影响，学习了一下仰慕已久却始终不得要领的AWK，
甚至还下载了著名的科尔尼汉写的《The AWK programming Language》并看完了第一章和后面的一些内容。</p>

<p>学习之后，发现这个东西其实还是很简洁的，同bash的配合确实很好，在某些应用场合下，处理文本、截取文本、调整文本，的确是利器。
但是，也必须注意到，这个东西确实已经是上古一代的东西了。不是说上古的东西就一定使用价值降低，不过AWK的作用和处理范围
已经大大地被Python和Ruby侵占。在Unix/C之下，他是足够简便的，对bash是很好的补充。如今已经是Ruby Python这些
script流行的年代，而这些脚本语言可以很大程度上替代AWK。AWK保留的优势仅仅是最简单的场合下，比如<code>{print $1}</code>之类时
显得足够简洁的优势。稍微复杂一些，如循环、分支判断一多，就显得不如Ruby Python了。</p>

<p>所以，看AWK的第一章以及简明教程就足够了。因为基本上也只要用到这些最简单的应用，写出优雅的bash命令。是用来写程序<strong>命令</strong>而不是程序<strong>文件</strong>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[patch and diff]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2013/02/05/patch-and-diff/"/>
    <updated>2013-02-05T10:52:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2013/02/05/patch-and-diff</id>
    <content type="html"><![CDATA[<p>patch和diff确实是个神奇的东西，用来对现有版本的升级是最好不过了。
好处在于一来不用停业务，二来可以明确到底改了多少东西。</p>

<h3>diff</h3>

<p>首先来说说diff，毕竟patch是从此处产生。</p>

<p>```
diff -ruNa src dest  > a.patch</p>

<p>-r 针对整个目录<br/>
-u 以合并的方式来显示文件内容的不同
-N 新文件做空白文件
-a 包含二进制内容，如jar包，class等
```</p>

<p>据说这个东西是perl的发明者创建的工具，主要用于比较源码，通常不带<code>-a</code>。</p>

<h3>patch</h3>

<p>patch就比较强大了。如果是更改一个目录下面，最常见的做法是进入该目录，然后执行</p>

<p><code>
patch -p1 &lt; ../a.patch
</code></p>

<p>随后，两个目录就会变得一模一样了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ssh-key]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2012/06/29/ssh-key/"/>
    <updated>2012-06-29T16:18:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2012/06/29/ssh-key</id>
    <content type="html"><![CDATA[<p>有些东西没用只是因为你的不习惯。一旦你开始用了，可能就会觉得之前的不采用是多么的傻。<strong>ssh-key</strong>登录就是这样一类东西。</p>

<p>一直以来没搞懂每次输入一个密码有那么麻烦的吗？去哪个站点不要登录啊。但用了几次之后，发现加了key后才能彻底发挥出
console快速敏捷的威力。这个比每次输入密码的体验好多了。更重要的，当机器很多很多，比如几十台上百台的时候，那省下的功夫
和能做的事情可就不是一点点了。当然，我并不理解为什么不用保存登录密码的方式，而是兜圈子采用这么一种办法。细想下来可能
和linux系统是多用户的系统这个特性相关。因为实质上的ssh-key登录是另外一个东西。可参见<a href="http://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html">这篇</a>入门的文章。</p>

<p>要想使用公钥登录方式，可以分为两步：</p>

<ol>
<li>生成公钥私钥对，会存放在<code>.ssh/id_rsa,  .ssh/id_rsa.pub</code>中，这是通过命令 <code>$ssh-keygen</code>来操作的</li>
<li>如果已经生成过了，那以后增加其他机器就可以直接执行这步，无需每次都生成公钥私钥。将公钥上传到远程服务器，远程主机会
把他们存放在<code>.ssh/authorized_keys</code>中。其实就是每个client增加一条记录。执行的命令是<code>$ ssh-copy-id user@host</code></li>
</ol>


<p>弄好以后，发现做起事情来确实快多了。</p>

<p>Update: 有些机器上需要给出额外的参数<code>ssh-copy-id -i ~/.ssh/id_rsa.pub git@host</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Arp 绑定]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2012/04/23/arp-binding/"/>
    <updated>2012-04-23T11:46:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2012/04/23/arp-binding</id>
    <content type="html"><![CDATA[<p>通过ftp备份老是报告登录失败。检查过后，网管告知我们是ip被抢。照理是需要网管执行纪律的，但是这个我就不越俎代庖，反正
解决问题为主。而且即便执行纪律也不保证下次就不会发生。于是想起来直接绑定arp和ip，这样可以<strong>根除</strong>此类问题。</p>

<p>主要参考了<a href="http://www.xxlinux.com/linux/article/network/security/20070809/9234.html">Linux下绑定IP和MAC地址，防止ARP欺骗</a>.</p>

<p>1.检查当前arp</p>

<p><code>bash
[root@ngntest ~]# arp -a
? (192.168.203.22) at 00:A0:D1:E5:D1:A9 [ether] on eth0
</code></p>

<p>2.建立一个mac->ip的对应文件： ip-mac, 将IP和MAC写入才文件</p>

<p><code>bash
echo '192.168.202.19 00:26:b9:4c:8d:af' &gt; /etc/ip-mac
</code></p>

<p>3.手动执行绑定</p>

<p><code>bash
[root@ngntest ~]# arp -f /etc/ip-mac
</code></p>

<p>上面的内容也可以存入<code>/etc/rc.d/rc.local</code> ,这样可以实现开机自动绑定。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What is Numa and the effect of it]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2012/04/08/what-is-numa-and-the-effect-of-it/"/>
    <updated>2012-04-08T22:38:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2012/04/08/what-is-numa-and-the-effect-of-it</id>
    <content type="html"><![CDATA[<p>研究mongod的时候，知道了一个关于cpu的概念--numa，但又不知道干嘛的。只知道需要在前面加上numactl来执行:</p>

<p><code>numactl --interleave=all mongod --dbpath /data/db --fork  --logpath /data/db.log</code></p>

<p>而拜读了这篇<a href="http://blog.jcole.us/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/">mysql 和 numa架构关联</a>
的文章，让人豁然开朗。</p>

<p>实际上，numa的本质就是牵涉到如何对内存进行分配，是一个在多cpu、多核中引入的概念。</p>

<p>比如，一个cpu时，那么全部的内存自然只有这个u可用。 但是，2个时呢? 如果一个u里面又有多个核心时，该怎么处理呢？</p>

<p>简而言之，numa的方法是让内存按cpu所属的node进行隔离，好处是提高了内存分配的公平性。但是对于mongod mysqld这样会
吃尽内存的应用，这种确保公平的分配方案并不好。因为根本没有其他核心需要用内存，但需要用内存的核心却会吃不饱。所以需要加上参数，使得这种公平性被取消，从而提高整体效能，其实就是发挥出mongod和mysqld的能力。因为这些应用都是单进程多线程的应用。</p>
]]></content>
  </entry>
  
</feed>
