<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[分类: 技术 | Hegel2011的博客]]></title>
  <link href="http://octopresszhangyu.herokuapp.com/blog/categories/技术/atom.xml" rel="self"/>
  <link href="http://octopresszhangyu.herokuapp.com/"/>
  <updated>2015-01-03T19:30:51+08:00</updated>
  <id>http://octopresszhangyu.herokuapp.com/</id>
  <author>
    <name><![CDATA[Hegel 2011]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[独一无二者计数问题（ count-distinct）]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/17/du-%5B%3F%5D-wu-er-zhe-ji-shu-wen-ti-%28-count-distinct%29/"/>
    <updated>2014-12-17T16:14:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/17/du-[?]-wu-er-zhe-ji-shu-wen-ti-(-count-distinct)</id>
    <content type="html"><![CDATA[<p>最近分析一个大日志文件，9亿条记录近300GB的数据。终于体会到一点大数据处理的意思。</p>

<p>之前根据日志，统计出里面各个域名的pv还算简单。为了开发方便，利用了Redis，开10个java线程，分别扫描不同的行，并把domain做关键字写入redis并不断计数，最后从中读出全部的值并排序。
整个过程主要开销在扫描方面。此时瓶颈出在redis上，基本上5个java线程可以把redis的cpu性能榨干。</p>

<p>9亿条数据分析出来了七十几万个域名，而redis处理70w个key，消耗的内存在100MB以内，所以整个运行跑上几个小时就能得到想要的结果了。</p>

<p>但是，客户进一步提出要分析每个domain下独立访问的用户数量是多少。这下子可就犯难了。
因为按照传统的做法，碰到需要计算独立用户的需求会建立一个集合，然后把标识往里push，最后获取一下这个set的大小，就可以得到独立用户的数量。
然而，如果对70w个域名都分别建立一张访问用户的set，则存储的开销实在太大。这意味着key-value的数量将是70w的几千甚至几万倍。
然后看了一下redis新增加的数据结构类型，发现redis中的hyperloglogs是为此种任务而生的。</p>

<h2>HyperLogLog和count-distinct problem</h2>

<p>建立一个集合并把数据放入，最后计算集合的大小是一种精确的求值方式。而HyperLogLog则是一种会损失一些细节但可以获得很好的近似值的估算方式。</p>

<p>这种算法的核心思想就是MD5+Bitmap。通过某种Hash算法，比如MD5，可以把千变万化的取值收敛成有限的值，而因为这些值也很大，所以可以认为重复的比例会很低。然后，应用Bitmap来表示这些映射结果是否已存在，最后就是计算这个Bitmap中已存在值的数量。尽管损失一些细节，也不是完全精确，但结果是足够准确了。而经过Hash的收敛，再经过Bitmap的收敛，对空间的需求就会变得少了许多许多，也就可以应用于更多关键字的计数。</p>

<p>以我自己对某个域名按两种方式都运行后得到的结果，分别对比如下：</p>

<p>精确的：1687，估计的：1685<br/>
精确的：93869，估计的：94097<br/>
精确的：305084，估计的：305281</p>

<p>而这种方式最大的好处，自然就是对count-distinct这类问题统计起来毫无压力了,同时得到的数据也足够好用了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[并发的ab测试和校验码对并发状况处理的盲区]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/12/11/bing-fa-de-abce-shi-he-xiao-yan-ma-dui-bing-fa-zhuang-kuang-chu-li-de-mang-qu/"/>
    <updated>2014-12-11T21:55:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/12/11/bing-fa-de-abce-shi-he-xiao-yan-ma-dui-bing-fa-zhuang-kuang-chu-li-de-mang-qu</id>
    <content type="html"><![CDATA[<p>某个报障称我们的短信轰炸拦截无效，听到后感觉比较奇怪，因为此限制已经加上并且经过测试验证。
但提供的素材上，单个用户确实同时收到了多条短信。于是又检查了一遍代码，发现问题可能出在并发上。</p>

<p>限制的过程是这样的：</p>

<ol>
<li>取出session中的校验码并与请求中的参数进行比较，通过的进入第2步，如失败则直接进入第3步；</li>
<li>发送短信；</li>
<li>刷新校验码。</li>
</ol>


<p>而如果扫描软件获取验证码后，同时交给多个线程并发发起请求，因为第一步执行的速度较快，而下发短信的请求处理较慢，
极其可能在执行第3步之前，另外几个请求也都通过了第一步的检查，从而可以进行第二步。</p>

<p>然后就是要验证这种猜测是否成立。由于扫描软件并不是我的，所以需要自己模拟这个请求，而又由于一些陷阱，导致整个验证也
颇费了一番周折。</p>

<h3>第一个坑： ! 和 &amp;都是shell的特殊字符</h3>

<p>最简单的模拟无非就是ab测试（ApacheBench），</p>

<p><code>ab -c 5 -n 10  http://xxx.com/portal/get\!validate.action?user_id=1xxxx\&amp;verfiyCode=5614</code></p>

<p>但是，一开始并没有在!和&amp;前面加上转移符号，所以运行失败</p>

<h3>第二个坑： 需要提前放入session</h3>

<p>一开始并没有搞清楚shell执行ab失败只是因为缺乏转义符号，于是尝试使用编写客户端代码解决。首先使用了Java的Jersey，
因为手头一个项目最近使用这个也比较顺手。运行之后发现每次都是返回404的错误。而在浏览器中，即使验证码不对，也会显示
正确的jsp。换了一台机器后，发现自己犯了个低级错误，因为验证码是存放在session里面的，而Jersey的普通请求不会
带cookie上去，因此就得到了错误的响应。</p>

<p>于是想着给Jersey的请求加上cookie消息头。一番考察后，被告知Jersey原生态并不支持直接加cookie，于是决定还是换用
ruby的rest-client。</p>

<p>```ruby
require 'rest-client'</p>

<p>jsp = "http://xxx.com/portal/";
passportUrl = 'http://xxx.com!validate.action?user_id=1xxxxxx&amp;verfiyCode=9813';</p>

<p>def s
  response = RestClient.get(jsp)
  @cookies = response.cookies</p>

<p>  @cookies['JSESSIONID'] = '74113695C0FB915393AE69DD63EAE088'
  p @cookies
  #puts response.body</p>

<p>  5.times do |n|</p>

<pre><code> response = RestClient.get(passportUrl, cookies: @cookies)
</code></pre>

<p>  end
  puts response.body
end</p>

<p>s()
```</p>

<p>手工填入浏览器中的校验码，运行正常。但ruby的单线程运行方式下，
模拟不出并发的效果，所以还是需要回到ab测试上。</p>

<p>最后的结果倒是很简单，给路径加上转义并添加cookie头即可：</p>

<p><code>ab -c 5 -n 10 -H "Cookie: JSESSIONID=74113695C0FB915393AE69DD63EAE088;" http://xxx.com/portal/get\!validate.action?user_id=1xxxx\&amp;verfiyCode=5614</code></p>

<p>这条命令基本上可收到5条短信，因为并发是5个。</p>

<h3>解决的办法</h3>

<p>最偷懒且管用的办法是使用<code>synchronized</code>关键字。需要注意的是两点：</p>

<p>第一， synchronized锁住的只是对象对应的代码段，所以适用于单例对象或者是static method。也可以通过
下面的方式，让锁住类对象来实现static的效果。</p>

<p>```java</p>

<pre><code>   synchronized (Controller.class) {  

    }
</code></pre>

<p>```</p>

<p>第二， 因为是只有一个线程可以执行代码，这个锁的影响还是很大的，所以要确保锁住的代码快足够小，操作足够快，
才不至于影响业务的性能。在此采用这么粗的锁，也是因为从session中验证校验码并删除是足够短的处理逻辑。</p>

<p>```java
synchronized private static void validCode(HttpSession sesson, String code) {
  result = false;
  if (StringUtils.equal(session.getAttribute("rand1"), code)) {</p>

<pre><code>result = true;
</code></pre>

<p>  }
  session.removeAttribute("rand1");
  return result;
}
```</p>

<h3>得到的教训</h3>

<p>部分业务逻辑在设计和实现时必须考虑并发的情况，尽管这个确实有点难度。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tomcat7 采用 Redis作为session Store - 2]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/11/19/tomcat7-cai-yong-rediszuo-wei-session-store-2/"/>
    <updated>2014-11-19T15:57:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/11/19/tomcat7-cai-yong-rediszuo-wei-session-store-2</id>
    <content type="html"><![CDATA[<p>在<a href="/blog/2014/07/14/tomcat7-cai-yong-rediszuo-wei-session-store/">Tomcat7 采用 Redis作为session Store</a>中，使用了redis作为tomcat的session共享。
在打过几个补丁后，基本也算运作正常。只是偶尔总是有些null的session需要定期清理。而当时的作者已经近2年没再处理相关的pull request，所以我提交到了另外一个库中。</p>

<p>上个月发现作者又回来了，接受处理了一系列的pull request并且还增加了一些新的配置。于是做了一下更新。</p>

<p>原本提过需要3个包：</p>

<ol>
<li><del>tomcat-redis-session-manager-1.2-tomcat-7.jar</del></li>
<li><del>jedis-2.0.0.jar</del></li>
<li><del>commons-pool-1.3.jar</del></li>
</ol>


<p>这次作者终于在readme中也加以了描述，并且更新了版本：</p>

<ol>
<li>tomcat-redis-session-manager-VERSION.jar</li>
<li>jedis-2.5.2.jar</li>
<li>commons-pool2-2.2.jar</li>
</ol>


<p>在context.xml中的配法也做了一些调整，主要是类名发生了变化，
```xml
<Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" />
&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager"</p>

<pre><code>     host="localhost" &lt;!-- optional: defaults to "localhost" --&gt;
     port="6379" &lt;!-- optional: defaults to "6379" --&gt;
     database="0" &lt;!-- optional: defaults to "0" --&gt;
     maxInactiveInterval="60" &lt;!-- optional: defaults to "60" (in seconds) --&gt;
     sessionPersistPolicy="ALWAYS" &lt;!-- optional: defaults to "DEFAULT" --&gt; /&gt;
     sessionPersistPolicies="PERSIST_POLICY_1,PERSIST_POLICY_2,.." &lt;!-- optional --&gt;
     sentinelMaster="SentinelMasterName" &lt;!-- optional --&gt;
     sentinels="sentinel-host-1:port,sentinel-host-2:port,.." &lt;!-- optional --&gt;
    connectionPoolMaxIdle="20"
     connectionPoolMaxTotal="500" 
</code></pre>

<p> /></p>

<p>```</p>

<p>另外就是增加了sessionPersistPolicies，建议选择<code>SAVE_ON_CHANGE</code>，如果选择<code>ALWAYS_SAVE_AFTER_REQUEST</code>，更容易诱发写竞争。而且有些场合，如果在request结束之后再写入，
中间的状态可能时间会拖得太长。如果真的对竞争情况很敏感的场合，就需要自己手动设置锁。</p>

<h3>github上把原作者的提交合并到自己的库中</h3>

<p>同把自己的修改贡献给对方类似，只不过这种pull request需要换成base是自己的库，而head则是原作者库，然后新建pull request，github就会列出发生过的变化。
这时候又会产生两种结局，其一是github可以自动合并，则再点击按钮即可，另一种是自动合并失败，会提示在本机先建分支，再pull原作者的分支，冲突解决（修改完毕）后合并回自己的主分支，
然后再push到github。push成功后，github会自动关闭这个pull request。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx 处理Spring 静态资源的配置]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/10/14/nginx-chu-li-spring-jing-tai-zi-yuan-de-pei-zhi/"/>
    <updated>2014-10-14T13:19:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/10/14/nginx-chu-li-spring-jing-tai-zi-yuan-de-pei-zhi</id>
    <content type="html"><![CDATA[<p>用Nginx处理静态资源是挺常见的一个事情，自从使用了Spring，也经常直接利用Spring的处理静态文件的功能，也能打上Etag。避免流量传输。
但是近来发现，Spring处理静态资源后，对静态文件获取的请求浏览器还是会发起，只是每次都是返回304。所以想继续借助Nginx给Spring的静态资源打上expire的标记。</p>

<p>需求也算简单：</p>

<ol>
<li>基于app toolbar的动态请求转发给java</li>
<li>gif,png，js等nginx直接处理，并加expire 3h；</li>
<li>部分.js请求如t.js还是转给java，有效期为0；</li>
<li>敏感文件不会被nginx处理，如web.xml无法被nginx转走</li>
</ol>


<p>因为目前Spring的静态资源单独存放在和WEB-INF并排的目录下，所以利用Nginx配置就大为简单了，只要限制路径名称即可。</p>

<p>```</p>

<pre><code>    location /toolbar {
        root   html;
        proxy_pass http://192.168.203.198:8080;
    }
    location ~ /toolbar/static {
        root   html;
        if (-f $request_filename) {
            expires 1d;
            break;
        }
    }
    location = /toolbar/enter/t.js {
        root   html;
        proxy_pass http://192.168.202.72:8080;
    }
</code></pre>

<p>```</p>

<p>然后在nginx的html目录下建立目录<code>toolbar</code>，并在其增加一个符号连接<code>ln -s /home/web/apache-tomcat-7.0.56/webapps/toolbar/static static</code>，就可以实现上述要求了。</p>

<p>这里面用到了几种Nginx的配置。</p>

<ol>
<li><code>location /toolbar</code>，这是最基本的匹配字符串的表达方式，优先级一般情况下也最低，然而<code>^~</code>是一个例外，它的优先级比下面的正则要高。</li>
<li><code>location ~ /toolbar/static</code>，这个是用到了正则表达式的匹配，优先级要高于基础的只比较字符。</li>
<li><code>location = /toolbar/enter/t.js</code>，这是优先级最高的匹配符，要求uri完全相等。</li>
</ol>


<p>如果需要使用正则表达式匹配，则必须使用<code>~</code>或者<code>~*</code>，其中后者和前者的区别是不区分大小写。</p>

<p>整个匹配顺序是：</p>

<ol>
<li>对<code>=</code>进行匹配，有相符的就停止；</li>
<li>对所有的非正则表达式（为使用~ 和 ~*）进行匹配，如果遇到<code>^~</code>则也停止，否则全部比对完毕后，最接近的匹配将被选用作为候选，随后进入3匹配正则表达式；</li>
<li>正则表达式按定义的顺序进行匹配，有匹配的则停止，即可选用刚刚匹配的正则表达式，如没有匹配的正则，则选用2中得到的结果。</li>
</ol>


<p>因此对静态资源的选择，可以加上<code>~</code>，也可以不加。但为了避免今后配置的冲突，还是让静态资源的优先级高一些来的好。</p>

<p>随后，可以使用下面的链接进行测试，看看是否满足需求：</p>

<p>http://192.168.203.198/toolbar/enter/t.js,<br/>
http://192.168.203.198/toolbar/static/images/logo1.png,<br/>
http://192.168.203.198/toolbar/WEB-INF/web.xml</p>

<p>前面两个应该得到返回内容，最后一个应该获得报错。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web容器中通过Spring添加Job任务]]></title>
    <link href="http://octopresszhangyu.herokuapp.com/blog/2014/09/11/webrong-qi-zhong-tong-guo-springtian-jia-jobren-wu/"/>
    <updated>2014-09-11T21:59:00+08:00</updated>
    <id>http://octopresszhangyu.herokuapp.com/blog/2014/09/11/webrong-qi-zhong-tong-guo-springtian-jia-jobren-wu</id>
    <content type="html"><![CDATA[<p>实际投入使用的Web站点总有很多例行任务要做，习惯的做法是利用操作系统的crontab定期执行脚本或者Java程序。
在更早的时候，曾经试过quartz，但后来因为quartz创建的线程属于JVM而不是Web容器，导致停止或
重新部署应用时线程并未终止，因此后来跑java程序例行任务的话，主要就
是单独运行jar文件。</p>

<p>时过境迁，了解到Spring已经接管了定时任务的线程处理，之前在
Web容器里跑多线程任务的最大隐患已经不存在了，所以尝试了一下在
Spring中使用例行更新。</p>

<p>这样做最大的好处当然就是代码集中，容易维护也容易部署。</p>

<h3>功能说明</h3>

<p>整个功能并不复杂，需要对redis中的设备号列表进行遍历，对每一个
号码调用远程接口获取该号码的一些动态变化的信息。取得后，这些信息
的时效时间是6小时，在失效前的10分钟内，需要再次调用远程接口刷新缓存。</p>

<p>因为整个功能的瓶颈在于远程调用，为了提高并发，
调用远程接口采取多线程的方式。而遍历的性能极好，使用单线程就够了。</p>

<h3>使用组件</h3>

<p>采用Java中线程的Executors实现起来最简单直接。Executors实质上就是一个
线程池，每塞给一个号码，就调用派发一个线程进行处理。如果没有线程可派，
则放入队列中，如队列满了则会依据设置再增加线程数量。</p>

<p><code>java
private TaskExecutor taskExecutor
</code></p>

<p>Executor确实是一个比较好的多线程编程方式，融合了Actor模式和队列，
使用起来也比较方便。</p>

<p>Executors可以由spring进行注入，在这个任务里比较合适的是采用ThreadPool*</p>

<p>```xml</p>

<pre><code>&lt;bean id="taskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor"&gt;
    &lt;property name="corePoolSize" value="5" /&gt;
    &lt;property name="maxPoolSize" value="10" /&gt;
    &lt;property name="queueCapacity" value="2500" /&gt;
&lt;/bean&gt;
</code></pre>

<p>```
corePoolSize是例行打开的线程数，queueCapacity是在没有core线程处理时的排队数量，
当超过这个数量时，会再启动线程直到maxPoolSize。如果都使用完毕，则可指定溢出时的抛弃处理方式。</p>

<p>派发任务由<code>taskExecutor.execute(new PollItInterfaceTask(mdn))</code>表达，
要同步的数据通过mdn传入。</p>

<p>此外，因为遍历的线程执行速度快，而workers可能需要更长时间才能完成队列中的任务，
为防止重复提交设置了一个多线程会并发访问的集合<code>private Set&lt;String&gt; mdnInQueue = new ConcurrentSkipListSet&lt;String&gt;(); //用于记录已安排执行但还未执行的号码</code>
。整个代码的情况如下:</p>

<p>```java
package com.sanss.toolbar.job;</p>

<p>import java.util.Date;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.TimerTask;
import java.util.concurrent.ConcurrentSkipListSet;</p>

<p>import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.junit.Assert;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.core.task.TaskExecutor;</p>

<p>import com.sanss.toolbar.service.CacheItInterfaceQueryService;</p>

<p>/<em>多线程发起的、向IT抓取用户套餐信息的线程池执行者，由spring中触发，根据接口run()</em>/
public class PollItInterfaceTaskExecutor  implements Runnable {</p>

<pre><code>private static Log logger = LogFactory.getLog(PollItInterfaceTaskExecutor.class);
private Set&lt;String&gt; mdnInQueue = new ConcurrentSkipListSet&lt;String&gt;(); //用于记录已安排执行但还未执行的号码
@Autowired
CacheItInterfaceQueryService cacheItInterfaceQueryService;

/*实际被多线程执行的任务,获取在队列中存放的mdn*/
private class PollItInterfaceTask implements Runnable {
    private String mdn;
    public PollItInterfaceTask(String mdn) {
        this.mdn = mdn;
    }

    public void run() {
        cacheItInterfaceQueryService.setCacheFlux(mdn);
        mdnInQueue.remove(mdn);
        Thread currentThread = Thread.currentThread();  // 获得当前的线程  
        String threadName = currentThread.getName();  
        logger.debug(threadName + ": 刷新下面号码的cache: " + mdn);
    }
}

private TaskExecutor taskExecutor;

public PollItInterfaceTaskExecutor(TaskExecutor taskExecutor) {
    this.taskExecutor = taskExecutor;

}

//任务出发后，被run自动执行的任务。首先获得所有需要提前取得IT流量信息的hashkey集合，随后遍历集合分别取出相关的一系列mdn，
//之后根据mdn检查ttl信息，发现小于500秒就安排Executor执行任务。
public void doit() {
    Set&lt;String&gt; tlbKeys = cacheItInterfaceQueryService.getAllTlbsetQueryList();
    int total = 0; //号码列表总数
    int count = 0; //本轮需要刷新的
    for (String hshkey : tlbKeys) {
        Map&lt;String, String&gt; mdns = cacheItInterfaceQueryService.getAllFieldsByAKey(hshkey);
        for(String mdn : mdns.keySet()) {
            long ttl = cacheItInterfaceQueryService.ttlFlux(mdn);
            if (ttl &lt; 500 ) {
                if (!mdnInQueue.contains(mdn)) {
                    mdnInQueue.add(mdn);
                    taskExecutor.execute(new PollItInterfaceTask(mdn));
                    count++;
               }
            }
            total++;
        }
    }
    logger.info("本轮刷新"+count+"个记录, 共有"+total+"个记录");
}

@Override
public void run() {
    // TODO Auto-generated method stub
 System.out.format("开始执行 %s ...%n", new Date());  
    doit();
}
</code></pre>

<p>}</p>

<p>```</p>

<p>CacheItInterfaceQueryService是项目中的一个服务模块，负责具体设置缓存。</p>

<p>```xml</p>

<!-- 定期去IT接口轮训的部署 -->


<pre><code>&lt;bean id="taskExecutor" class="org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor"&gt;
    &lt;property name="corePoolSize" value="5" /&gt;
    &lt;property name="maxPoolSize" value="10" /&gt;
    &lt;property name="queueCapacity" value="2500" /&gt;
&lt;/bean&gt;

  &lt;bean id="pollItInterfaceTaskExecutor" class="com.sanss.toolbar.job.PollItInterfaceTaskExecutor"&gt;
       &lt;constructor-arg ref="taskExecutor" /&gt;
 &lt;/bean&gt;

&lt;bean id="springScheduleExecutorTask"  
    class="org.springframework.scheduling.concurrent.ScheduledExecutorTask"&gt;  

    &lt;property name="runnable" ref="pollItInterfaceTaskExecutor" /&gt;  

    &lt;property name="delay" value="1000" /&gt;  
    &lt;!-- 每次任务间隔 一分钟--&gt;  
    &lt;property name="period" value="60000" /&gt;  
&lt;/bean&gt;  

 &lt;bean id="springScheduledExecutorFactoryBean"  
    class="org.springframework.scheduling.concurrent.ScheduledExecutorFactoryBean"&gt;  
    &lt;property name="scheduledExecutorTasks"&gt;  
        &lt;list&gt;  
            &lt;ref bean="springScheduleExecutorTask" /&gt;  
        &lt;/list&gt;  
    &lt;/property&gt;  
&lt;/bean&gt;  
</code></pre>

<p><code>``
避免不了的配置如上，</code>taskExecutor<code>已经在前面描述过，第二段的</code>pollItInterfaceTaskExecutor<code>就是把线程池执行者
作为参数传给自己编写的任务的构造函数，然后第三段定义一个周期执行的任务，设置好执行的间隔，runnable要提供自己编写的业务类（第二段中的内容），
最后第四步把这个周期任务交给Spring的</code>ScheduledExecutorFactoryBean`工厂来负责管理。
需要注意的是，ScheduledExecutorFactoryBean是spring4中的写法，在spring3中还是另一套描述方式，虽然功能差不多。
但在版本升级时，这是一个不大不小的坑。</p>
]]></content>
  </entry>
  
</feed>
